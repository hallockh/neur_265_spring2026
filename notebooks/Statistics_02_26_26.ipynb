{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFhbVB0MzaTjADDxDhodEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallockh/neur_265_spring2026/blob/main/notebooks/Statistics_02_26_26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics for Neuroscientists\n",
        "\n",
        "This notebook will discuss **descriptive** and **inferential** statistics, and introduce ways to implement them in Python.\n",
        "\n",
        "### By the end of this notebook, you will be able to:\n",
        "\n",
        "* Identify when to use descriptive or inferential statistics\n",
        "* Apply the appropriate statistical tests to compare two groups\n",
        "* Use the stats package from SciPy to run simple tests in Python\n",
        "* Test e-phys metrics between different interneuron types\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EvkdoGKpqxDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part One: Population vs sample distributions\n",
        "\n",
        "**Descriptive statistics** summarize the main features of a data set.\n",
        "\n",
        "It's important to distinguish between the following:\n",
        "\n",
        "* **Observation**: result from one trial of an experiment (like one ISI)\n",
        "* **Sample**: results from multiple independent trials (all ISIs)\n",
        "* **Population**: the *ground truth*; all possible ISIs that could be seen\n",
        "\n",
        "Distributions differ in their **location** (mean, $\\\\mu$) and **spread** (standard deviation, $\\\\sigma$). Below, we'll define a **population distribution** and plot it."
      ],
      "metadata": {
        "id": "fHn9N0l_rMQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our necessary toolboxes and tell matplotlib to plot inline\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Decide on a mean and a standard deviation\n",
        "mu, sigma = 3, 2\n",
        "\n",
        "# Use np.random.normal to create a distribution of 10,000 points with our given mu & sigma\n",
        "pop = np.random.normal(mu, sigma, 10000)"
      ],
      "metadata": {
        "id": "ais0ngbBrlZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram with 30 bins\n",
        "# Giving it the argument density=True will plot normalized counts\n",
        "# This will create a probability density (rather than raw counts)\n",
        "plt.hist(pop, 30, density=True)\n",
        "plt.axvline(mu,color='r')\n",
        "plt.title('Population distribution of 10,000 points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YXvbuoAgrucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are various ways we can describe the distribution of the dataset, beyond the standard deviation:\n",
        "\n",
        "* Range (minimum and maximum)\n",
        "* Variance ($\\\\sigma^2$)\n",
        "* Standard Error of the Mean (S.E.M., $\\\\sigma/\\\\sqrt{n}$)\n",
        "* Confidence Intervals\n",
        "\n",
        "We can easily get many of these descriptive statistics by using the `scipy stats` package method `describe()`. [Documentation here.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.describe.html)"
      ],
      "metadata": {
        "id": "na83NXSZrzFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "stats.describe(pop)"
      ],
      "metadata": {
        "id": "F66gjMPxsFeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a normal distribution from a mean of 3 but with limited points, so these values are *just* slightly off. You'll also notice that the variance is indeed our standard deviation (2) squared.\n",
        "\n",
        "Our variable `pop` is the \\\"ground truth\\\" population. However, we'll rarely have *10,000* datapoints in our sample. So, let's generate a more realistic sample, and see how the mean compares."
      ],
      "metadata": {
        "id": "XUiOEdrmsUFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample distribution with less data points\n",
        "sample_mean, sample_sigma = 3, 2\n",
        "sample = np.random.normal(sample_mean, sample_sigma, 20)\n",
        "\n",
        "# Plot our histogram, with alpha to 0.5 which will make the chart slightly transparent\n",
        "plt.hist(pop, 30, alpha=0.5, density=True)\n",
        "plt.hist(sample, 30, alpha=0.5, color='r',density=True)\n",
        "plt.axvline(np.mean(pop),color='blue') # Take the mean and plot a vertical blue line\n",
        "plt.axvline(np.mean(sample),color='red') # Take the mean and plot a vertical red line\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FH2BmXFtse61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the descriptive statistics of our sample\n",
        "print(stats.describe(sample))"
      ],
      "metadata": {
        "id": "dUzQxuk3shmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Two: The Central Limit Theorem\n",
        "\n",
        "With fewer samples, the mean of the sample distribution tends to be further from the mean of the population distribution. This is known as the **central limit theorem**, which states that the distribution of sample means will become increasingly close to a normal distribution as the sample size increases, regardless of the shape of the population distribution."
      ],
      "metadata": {
        "id": "FRwZ-sjusqMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,5,figsize=(20,5),sharey=True)\n",
        "\n",
        "mu = 0\n",
        "\n",
        "sample_means = []\n",
        "\n",
        "# For each subplot, create a plot.\n",
        "for a in range(len(ax)):\n",
        "\n",
        "    # Make the sample size = to 3^(a+1)\n",
        "    sample_size = 3**(a+1)\n",
        "\n",
        "    # Calculate the mean of sample of sample_size designated above, 10000 times\n",
        "    for x in range(10000):\n",
        "        sample_dist = np.random.normal(mu, 10, sample_size) # Create a normal distribution with mu, sigma\n",
        "        sample_means.append(np.mean(sample_dist)) # Append the mean of this distribution\n",
        "\n",
        "    ax[a].hist(sample_means,color='teal',alpha = .5) # Plot the distribution of means\n",
        "    ax[a].set_title('sample size= '+ str(sample_size)+', mean = '+ str(np.round(np.mean(sample_means),3)))\n",
        "    ax[a].set_xlim([-20,20])\n",
        "    sample_means = [] # Reset the sample means\n",
        "\n",
        "plt.suptitle('Distributions of 10,000 sample means for a population with mean '+str(mu),fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-we6cpss2EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Three: Skewed Distributions\n",
        "\n",
        "However, not every population in nature is **normally distributed**. In fact, most populations are slightly skewed. Let's demonstrate a population distribution and sample distribution that is drawn from a [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution)."
      ],
      "metadata": {
        "id": "BibYcLQouwRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a skewed distribution of 10,000 points with our given mu & sigma\n",
        "pop_size = 10000\n",
        "sample_size = 100\n",
        "\n",
        "skewed_pop = np.random.gamma(7.5,1,pop_size)\n",
        "skewed_sample = np.random.gamma(7.5,1,sample_size)\n",
        "\n",
        "pop_stats = stats.describe(skewed_sample)\n",
        "sample_stats = stats.describe(skewed_pop)\n",
        "\n",
        "plt.hist(skewed_pop, 30, alpha = .3, density=True)\n",
        "plt.hist(skewed_sample, 30, alpha = .3, density=True)\n",
        "plt.axvline(pop_stats.mean,color='blue')\n",
        "plt.axvline(sample_stats.mean,color='orange') # plot the mean of the sample\n",
        "\n",
        "plt.legend(['Population','Sample'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uMMaX_b7u2_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might notice that with this skewed population, the mean is a pretty poor descriptor of both distributions. **When the skew is bad (*statistically bad*), we should report the median.**\n",
        "\n"
      ],
      "metadata": {
        "id": "afsSR0KPvBJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important notes:\n",
        "\n",
        "* <code>stats.describe()</code> doesn't give us the median (annoyingly) but `np.median()` can!\n",
        "* The `stats.skewtest()` method ([documentation here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html#scipy.stats.skewtest)) implements the [D'Agostino-Pearson skewness test](https://www.jstor.org/stable/2684359?seq=1), one of many different tests (e.g., the Kolmogorov-Smirov test) that can be used to check the normality of a distribution.\n",
        "* This code can return a statistic as well as a pvalue, if you designate it."
      ],
      "metadata": {
        "id": "mCTY36dSvSSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b>\n",
        "1. Rework the code directly above so that if the skew is significant (you can use <code>stats.skewtest()</code> for that!), plot and report the <b>median</b> instead of the mean.\n",
        "2. Rework our demonstration of the central limit theorem for a skewed, rather than a normal, population. Does the theorem still hold?"
      ],
      "metadata": {
        "id": "htEmP2-Wvmio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Four: Hypothesis Testing\n",
        "\n",
        "**Inferential statistics** generalize from observed data to the world at large\n",
        "\n",
        "Most often, the goal of our hypothesis testing is to test whether or not two distributions are different, or if a distribution has a different mean than the underlying population distribution.\n",
        "\n",
        "With the normal sample population we generated above, our **null hypothesis** is that the mean of our sample distribution is equal to 3. We want to test the probability that this is not true. Since we know our distributions are normal (they're generated from a normal distribution!) we can use **parametric statistics** to test our hypothesis.\n",
        "\n",
        "The SciPy stats package has [many hypothesis testing tools](https://docs.scipy.org/doc/scipy/reference/stats.html) (see Statistical Tests). First, we can use a one-way t-test to ask whether our population has a mean different than three."
      ],
      "metadata": {
        "id": "z0FHZ1oGv0QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mean, sample_sigma = 3, 2\n",
        "sample_pop = np.random.normal(sample_mean, sample_sigma, 20)\n",
        "stats.ttest_1samp(sample_pop,1)"
      ],
      "metadata": {
        "id": "YSTc0RTswETV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not surprisingly, if we create a normal distribution of mean 3, the distribution is not likely to be different than 3. However, what happens if we change the mean, standard deviation, or sample size?\n",
        "\n",
        "In most cases, we will be testing whether or not two distributions are different from eachother. In order to do so, we can use the independent t-test in our stats package: `stats.ttest_ind()`. If we had paired samples, we would use a dependent t-test [as seen here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html#scipy.stats.ttest_rel)."
      ],
      "metadata": {
        "id": "2yUpMH7UwKg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two distributions and test whether they're different\n",
        "pop_1 = np.random.normal(3,2,20)\n",
        "pop_2 = np.random.normal(5,2,20)\n",
        "\n",
        "stats.ttest_ind(pop_1,pop_2)"
      ],
      "metadata": {
        "id": "wUQJhuG1wW34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If one of our populations is skewed, however, we **cannot use a t-test**. A t-test assumes that the populations are normally distributed. For skewed populations, we can use either the [Mann-Whitney U](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy.stats.mannwhitneyu) (for independent samples, `stats.mannwhitneyu()`) or the [Wilcoxon Signed Rank Test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html#scipy.stats.wilcoxon) (for dependent/paired samples,`stats.wilcoxon()`)."
      ],
      "metadata": {
        "id": "BlG04Tr5wc5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skewed_pop = np.random.gamma(7.5,1,10000)\n",
        "comparison_pop = np.random.normal(8,2,20)\n",
        "\n",
        "stats.mannwhitneyu(skewed_pop,comparison_pop)"
      ],
      "metadata": {
        "id": "S1JTqMCtwiKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Five: Comparing ISI values in our Patch Seq dataset\n",
        "\n",
        "Let's work with some real data to apply what we've learned above. Below, import your <code>patch_seq_expanded</code> dataset as a Pandas dataframe called <code>patch_seq</code>."
      ],
      "metadata": {
        "id": "VUYcIQna4dvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here!\n"
      ],
      "metadata": {
        "id": "_XQ9HpTD4iSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task</b>: Create a plot with two subplots. The left should be a histogram of our ISI values ('ISI') for 'Sst' and 'Pvalb' cells. The right should be a boxplot of the ISI values ('ISI'). You can create a histogram of one column of a <code>dataframe</code> by using the syntax <code>df['column_name']</code>."
      ],
      "metadata": {
        "id": "PV7PzihF-Mmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here! Start with defining your subplot axes\n",
        "\n",
        "# Next, make your histogram (see code cell in part three of this notebook for an example of how to make overlapping histograms)\n",
        "\n",
        "# Next, make your boxplot (see our notebook from Tuesday!)"
      ],
      "metadata": {
        "id": "_cja3ig8-R8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task</b>: Determine whether these two samples of ISI values are statistically different! Write code that first checks whether or not the distributions are skewed, and then runs the appropriate statistics."
      ],
      "metadata": {
        "id": "dIzqV4H0GWR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "THfRn4hOG2R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task</b>: Re-create a scatterplot of ISI values vs. Fast Trough values for 'Sst' and 'Pvalb' neurons, with 'Sst' neurons in blue, and 'Pvalb' neurons in red (*hint:* look at our notebook on plotting from Tuesday!) Run linear regressions on each group of interneurons do see whether the associations are statistically significant!"
      ],
      "metadata": {
        "id": "8g7fJC_vlC_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the linear regression toolbox from scipy\n",
        "\n",
        "from scipy.stats import linregress\n",
        "\n",
        "# Create your scatter plot!\n",
        "\n",
        "marker_types = patch_seq['Marker'].unique()\n",
        "\n",
        "# Run linear regressions on the two variables!\n",
        "\n",
        "for m_type in marker_types:\n",
        "\n",
        "  df = patch_seq[patch_seq['Marker'] == m_type]\n",
        "\n",
        "  slope, intercept, r, p, stderr = linregress(df['ISI'], df['Fast_Trough'])\n",
        "\n",
        "  print(f\"\\n{m_type}\")\n",
        "  print(f\"Slope: {slope}\")\n",
        "  print(f\"R^2: {r**2}\")\n",
        "  print(f\"p-value: {p}\")\n"
      ],
      "metadata": {
        "id": "0aAFcTBqlmj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}